{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "76b616b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b0543c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will import text from pdf file\n",
    "file = open(\"article1.txt\",\"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3be64538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='article1.txt' mode='r' encoding='cp1252'>\n"
     ]
    }
   ],
   "source": [
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5488bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word in text:\n",
    "#     print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "eb4ec60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to extract text from the file\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "\n",
    "for line in file:\n",
    "    for word in line:\n",
    "        text += word\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "772cb2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ram is a boy. Ram is king. Ram is a legend. Ram is the son of Raja Dasrath Ram.\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "stopword = list(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4e81b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now time to lead the small English model for processing the text\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "260d064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "32089f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a7f470e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ram is a boy. Ram is king. Ram is a legend. Ram is the son of Raja Dasrath Ram.\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "66e72f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In spaCy, a Doc object is a container for a sequence of tokens,\n",
    "# where each token is represented by a Token object.\n",
    "# The Token object has various attributes and methods that allow you\n",
    "# to access information about the token, such as its text, its lemma, its part-of-speech tag, etc.\n",
    "\n",
    "# The text attribute is one of the attributes of a Token object and represents the original string representation of the token as it appeared in the text. For example, if the original text was \"Hello, world!\", the tokens would be \"Hello,\" and \"world!\" and their text attribute would be \"Hello,\" and \"world!\", respectively.\n",
    "\n",
    "# By accessing the text attribute of each token in a spaCy document, you can extract the text of each token and store it in a list or process it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "41f4ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b02e441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ram', 'is', 'a', 'boy', '.', 'Ram', 'is', 'king', '.', 'Ram', 'is', 'a', 'legend', '.', 'Ram', 'is', 'the', 'son', 'of', 'Raja', 'Dasrath', 'Ram', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "25530357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the token in not clean \n",
    "# it contains punctions and end of line etc\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "baf13496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearly no end of line is included here \n",
    "# so here let's include include it\n",
    "punctuation += '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "61b79fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token for token in tokens if token not in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "77eb4d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ram', 'is', 'a', 'boy', 'Ram', 'is', 'king', 'Ram', 'is', 'a', 'legend', 'Ram', 'is', 'the', 'son', 'of', 'Raja', 'Dasrath', 'Ram']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "67187e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now our tokens in cleaned\n",
    "# let's calculate the word frequencies\n",
    "word_frequencies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "66936f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in doc:\n",
    "    if word.text.lower() not in punctuation:\n",
    "        if word.text.lower() not in stopword:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0b88ac8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ram': 5, 'boy': 1, 'king': 1, 'legend': 1, 'son': 1, 'Raja': 1, 'Dasrath': 1}\n"
     ]
    }
   ],
   "source": [
    "print(word_frequencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "17d70c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frequency = max(word_frequencies.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "098f3046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(max_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ef87b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find the key with maximum word frequency\n",
    "max_keys = []\n",
    "for key,value in word_frequencies.items():\n",
    "    if value == max_frequency:\n",
    "        max_keys.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9d25af96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ram']\n"
     ]
    }
   ],
   "source": [
    "print(max_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "520a0ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'everything', 'toward', 'them', 'are', 'somehow', 'seeming', 'forty', 'there', 'then', 'others', 'his', 'mine', '‘ve', 'take', 'of', 'four', 'other', 'whom', 'former', 'whereupon', '’m', 'if', '’d', 'please', 'therefore', 'yourselves', 'anyway', 'any', 'hers', 'now', 'eleven', 'twelve', 'again', 'part', 'your', 'as', 'throughout', 'thereby', 'when', 'unless', 'us', 'see', 'seems', 'ten', 'becomes', 'why', \"'s\", 'whatever', 'some', 'herein', '‘s', 'above', 'towards', 'upon', '‘re', 'also', 'has', 'go', 'elsewhere', 'whoever', 'whereafter', 'it', 'bottom', 'seemed', 'wherein', 'call', 'fifty', 'its', 'below', 'name', 'would', 'no', 'well', 'something', 'ca', 'here', 'these', 'regarding', 'thus', 'my', 'alone', 'anything', 'did', 'almost', 'two', 'amount', 'even', 'onto', 'few', 'doing', 'their', 'through', 'meanwhile', 'wherever', 'everyone', 'once', '’s', 'ours', 'hereupon', 'fifteen', 'always', 'serious', '’re', 'together', 'had', 'whole', '‘ll', 'twenty', 'just', 'noone', 'nine', 'under', 'latterly', 'nowhere', 'enough', 'so', 'whose', 'else', 'side', 'nobody', 'nevertheless', 'i', \"n't\", 'otherwise', 'back', 'her', 'during', 'show', 'could', 'move', 'to', 'himself', 'give', 'she', 'we', 'herself', 'n‘t', 'three', 'becoming', 'besides', 'this', 'though', 'thereafter', 'themselves', 'formerly', 'least', 'another', 'about', 'very', 'much', 'quite', 'who', 'anywhere', 'therein', 'eight', 'never', 'hereby', 'keep', 'does', 'or', 'along', 'several', 'one', 're', 'itself', 'am', 'while', 'amongst', 'thereupon', 'should', 'get', 'before', 'whither', '‘m', 'which', 'put', 'will', 'too', \"'ll\", 'may', 'both', 'become', 'the', 'only', 'myself', 'can', 'whereby', 'already', 'anyone', 'must', \"'ve\", 'full', 'latter', 'somewhere', 'cannot', 'our', 'six', 'whereas', 'how', \"'m\", 'afterwards', 'a', 'five', 'an', 'and', 'being', 'by', 'same', 'thru', 'in', '’ve', 'make', 'since', 'out', 'someone', \"'d\", 'have', 'for', 'third', 'such', 'him', 'n’t', '’ll', 'nor', 'really', 'until', 'every', 'front', 'where', 'many', 'behind', 'be', 'over', 'next', 'among', 'yourself', 'sixty', 'ever', 'beforehand', 'what', '‘d', 'against', 'but', 'on', 'hence', 'top', 'various', 'most', 'sometime', 'none', 'me', 'namely', 'indeed', 'although', 'hundred', 'might', 'using', 'rather', 'done', 'except', 'whenever', 'because', 'first', 'been', 'per', 'that', 'beyond', 'either', 'all', 'nothing', 'used', 'not', 'into', 'down', \"'re\", 'say', 'is', 'they', 'whether', 'yours', 'thence', 'you', 'across', 'still', 'however', 'perhaps', 'whence', 'than', 'last', 'at', 'yet', 'within', 'everywhere', 'further', 'seem', 'due', 'neither', 'off', 'empty', 'was', 'those', 'anyhow', 'own', 'each', 'became', 'made', 'were', 'hereafter', 'beside', 'he', 'less', 'more', 'via', 'mostly', 'with', 'often', 'moreover', 'after', 'do', 'between', 'up', 'sometimes', 'ourselves', 'without', 'around']\n"
     ]
    }
   ],
   "source": [
    "print(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f5c52191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now normalize the frequency\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word]/max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cc67f446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ram': 1.0, 'boy': 0.2, 'king': 0.2, 'legend': 0.2, 'son': 0.2, 'Raja': 0.2, 'Dasrath': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5ee42425",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokens = [sent for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5207479e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ram is a boy., Ram is king., Ram is a legend., Ram is the son of Raja Dasrath Ram.]\n"
     ]
    }
   ],
   "source": [
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "10b5a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate sentence score\n",
    "sentence_scores = {}\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.text.lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8de9c681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Ram is a boy.: 0.2, Ram is king.: 0.2, Ram is a legend.: 0.2, Ram is the son of Raja Dasrath Ram.: 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(sentence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c18a2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have to extract the 30 percent of the text with maximum scores\n",
    "from heapq import nlargest # the module which implements heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "deb2a930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_length = int(len(sentence_tokens)*.30)\n",
    "select_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a419df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to select (select_length) number on sentence \n",
    "summary = nlargest(select_length,sentence_scores, key = sentence_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3be6790f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Ram is a boy.]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c1becefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary = [word.text for word in summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "16c8af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = ' '.join(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cd36325d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ram is a boy.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fb129153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ram is a boy. Ram is king. Ram is a legend. Ram is the son of Raja Dasrath Ram.\n"
     ]
    }
   ],
   "source": [
    "# original text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036a77e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2855dcd1446957b995c617c7eb571a1440b2353b6f13a4547fcc7eb2a499362"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
