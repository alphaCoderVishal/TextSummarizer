{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#input text file\n",
    "readFlNm=\"input.txt\"\n",
    "#precentage of summarization\n",
    "percentageOfSummary=70\n",
    "#fetch stop words\n",
    "stopWords = set(stopwords.words('english'))\n",
    "#update stop words\n",
    "stopWords.update(['\"', \"'\", ':', '(', ')', '[', ']', '{', '}']) #'.',  ',', '?', '!', ';'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#using pos_tag get the tag of words\n",
    "def getTagsForWords(textLn2):\n",
    "    tokens=word_tokenize(textLn2)\n",
    "    tagged=pos_tag(tokens)\n",
    "    return(tagged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove stop words\n",
    "def remStopWordsOur(lineIn):\n",
    "    stopWords= {'i','a','and','about','an','are','as','at','be','by','com','for','from','how','in','is','it','not','of','on','or','that','the','this','to','was','what','when','where','who','will','with','the','www','your','is','am','some','you','your','I','A','And','About','An','Are','As','At','Be','By','Com','For','From','How','In','Is','It','Not','Of','On','Or','That','The','This','To','Was','What','When','Where','Who','Will','With','The','Www','Your','Is','Am','Some','You','Your','Was'}\n",
    "    rmdStopWordsLn = ' '.join(w for w in lineIn.split() if w.lower() not in stopWords)\n",
    "    return rmdStopWordsLn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#preprocessing the text and remove special characters\n",
    "def preprocessText(lineIn):\n",
    "    lineInLower=lineIn.lower()\n",
    "    lineInRmdSplChars=lineInLower.replace('.',' ').replace(';',' ').replace(',',' ').replace('?',' ').replace('!',' ').replace(':',' ')\n",
    "    return lineInRmdSplChars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Divide the given text into lines\n",
    "def getAllLines(lineIn):\n",
    "    lineInReplcByPeriod=lineIn.replace('.','.§').replace(';',';§').replace(',',',§').replace('?','?§').replace('!','!§').replace('\\n','§')\n",
    "    linesOriginal=lineInReplcByPeriod.split('§')\n",
    "    linesOriginal2=[item for item in linesOriginal if len(item)>0 ]\n",
    "    return linesOriginal2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Identify the noun position\n",
    "def getNounPositions(type,tagged):\n",
    "    nounPosi={}\n",
    "    for item in tagged:\n",
    "        if item[1]==type:\n",
    "            nounPosi[item[0]]=-1\n",
    "    \n",
    "    for key in nounPosi.keys():\n",
    "        regExpression=r'\\b'+key.lower()+r'\\b'\n",
    "        nounsi=[m.start() for m in re.finditer(regExpression, lineIn.lower())]\n",
    "#        print(key,nounsi)\n",
    "        nounPosi[key]=nounsi\n",
    "    return nounPosi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Identify the pronoun position\n",
    "def getProNounPositions(tagged):\n",
    "    proNounPosi={}\n",
    "    for item in tagged:\n",
    "        if item[1]=='PRP': #or item[1]=='PRP$':\n",
    "            proNounPosi[item[0].lower()]=-1\n",
    "    \n",
    "    for key in proNounPosi.keys():\n",
    "        regExpression=r'\\b'+key.lower()+r'\\b'\n",
    "        pronounsi=[m.start() for m in re.finditer(regExpression, lineIn.lower())]\n",
    "#        print(key,pronounsi)\n",
    "        proNounPosi[key]=pronounsi\n",
    "    return proNounPosi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Obtain nearest previous noun\n",
    "def getNearestPreviousNoun(NNP,posiOfPronoun):\n",
    "#    print('\\t',NNP)    \n",
    "    minimumDiff=len(lineIn)\n",
    "    nearKey=''\n",
    "    for keyNNP in NNP.keys():\n",
    "        for posNoun in NNP[keyNNP]:\n",
    "            if(posiOfPronoun>posNoun):\n",
    "#                print('\\t',posiOfPronoun-posNoun)\n",
    "                if(minimumDiff>(posiOfPronoun-posNoun)):\n",
    "                    minimumDiff=posiOfPronoun-posNoun\n",
    "                    nearKey=keyNNP\n",
    "#    print('\\t near key=',nearKey)\n",
    "    return nearKey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Replace pronoun by noun\n",
    "def pronounReplaceWithNearNoun(lineIn,PRP,NNP):\n",
    "    replacePRP=[]       \n",
    "    for key in PRP.keys():            \n",
    "        for pos in PRP[key]:\n",
    "            print('---------',key,'------',pos ,'-----')\n",
    "            nearNoun=getNearestPreviousNoun(NNP,pos)\n",
    "            replacePRP.append((key,pos,nearNoun))  \n",
    "#    print(PRP)\n",
    "#    print(replacePRP)\n",
    "    \n",
    "    replacePRP=sorted(replacePRP,key=lambda x:(-x[1],x[0],x[2]))\n",
    "    lineInReplacePronn=lineIn\n",
    "    for prpRep in replacePRP:\n",
    "        lineInReplacePronn=lineInReplacePronn[:prpRep[1]]+prpRep[2]+lineInReplacePronn[prpRep[1]+len(prpRep[0]):]\n",
    "    return lineInReplacePronn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Based on weightage obtain the priority of lines\n",
    "def obtainPriorotyOfALine(wtForLine):\n",
    "    orderdLinesByWt=np.argsort(wtForLine)\n",
    "    orderdLinesByWt=orderdLinesByWt[::-1]\n",
    "    priority=[0]*len(wtForLine)\n",
    "    \n",
    "    for i in range(len(wtForLine)):\n",
    "#        print(i,wtForLine[i],orderdLinesByWt[i])\n",
    "        priority[orderdLinesByWt[i]]=i\n",
    "    \n",
    "    sentWtAndPriority=[]\n",
    "    \n",
    "    for i in range(len(wtForLine)):\n",
    "        sentWtAndPriority.append((wtForLine[i],priority[i]))\n",
    "    \n",
    "    return sentWtAndPriority\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct summary by extraction method\n",
    "def obtainSummary(lineForCalc,lineForExtract,percentageOfSummary):\n",
    "    wtForLine=[0]*len(lineForCalc)\n",
    "    print('Calcualting wt for lines......')\n",
    "    for li in range(len(lineForCalc)):\n",
    "    #    print('\\t'+linesOriginal2[li])\n",
    "        wtForLn=0.0\n",
    "        preproccdLn2=preprocessText(lineForCalc[li])\n",
    "        wInL=preproccdLn2.split()\n",
    "        for w in wInL:\n",
    "            w=preprocessText(w)\n",
    "            if w in list(freqOfWords.keys()):\n",
    "    #            print('\\t\\t'+w+' '+str(freqOfWords[w]))\n",
    "                wtForLn=wtForLn+freqOfWords[w]\n",
    "        wtForLine[li]=(wtForLn/len(wInL))\n",
    "    #        print('\\t\\t'+lineForCalc[li]+' $'+str(wtForLine[li]))\n",
    "    \n",
    "    sentWtAndPriority=obtainPriorotyOfALine(wtForLine)\n",
    "    print(sentWtAndPriority)\n",
    "    numOfLinesInSummary=int((percentageOfSummary*len(lineForCalc))/100)\n",
    "    reducedSummary=[]\n",
    "    for li in range(len(lineForExtract)):\n",
    "        if(sentWtAndPriority[li][1]<numOfLinesInSummary):\n",
    "    #            print(li,sentWtAndPriority[li])\n",
    "            reducedSummary.append(lineForExtract[li])\n",
    "    return reducedSummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove week nm and month name\n",
    "def removeWeekNmMonthNm(NNP):\n",
    "    entries = ('january','february','march','april','may','june','july','august','september','october','november','december','monday','tuesday','wednesday','thursday','friday','saturday','sunday')\n",
    "    delKeys=[]\n",
    "    for key in NNP.keys():\n",
    "        if key.lower() in entries:\n",
    "            print(key)\n",
    "            delKeys.append(key)\n",
    "    \n",
    "    for key in delKeys:\n",
    "        del NNP[key]\n",
    "    return NNP\n",
    "\n",
    "with open(readFlNm,\"r\") as fileIn:\n",
    "        lineIn = fileIn.read()\n",
    "        linePreProcessed=preprocessText(lineIn)\n",
    "        rmdStopWordsLn= ' '.join(i for i in linePreProcessed.split() if i not in stopWords)\n",
    "        nt=len(rmdStopWordsLn.split())\n",
    "        freqOfWords = Counter(re.split(r'\\s+',re.sub(r'[.,;\\-!?]','',rmdStopWordsLn)))\n",
    "        for word, freq in freqOfWords.items():          \n",
    "            freqOfWords[word]=freqOfWords[word]/nt\n",
    "\n",
    "tagged=getTagsForWords(lineIn)\n",
    "NNP=getNounPositions('NNP',tagged)\n",
    "NNP=removeWeekNmMonthNm(NNP)\n",
    "#NN=getNounPositions('NN',tagged)\n",
    "#NNS=getNounPositions('NNS',tagged)\n",
    "PRP=getProNounPositions(tagged)\n",
    "\n",
    "linesOriginal2=getAllLines(lineIn)\n",
    "lineInReplacePronn=pronounReplaceWithNearNoun(lineIn,PRP,NNP)\n",
    "linesReplacedPronn2=getAllLines(lineInReplacePronn)\n",
    "print(percentageOfSummary)\n",
    "\n",
    "#perform the text summarization without pronoun replacement\n",
    "reducedSummaryWithoutReplc=obtainSummary(linesOriginal2,linesOriginal2,percentageOfSummary)\n",
    "#perform the text summarization with pronoun replacement\n",
    "reducedSummaryWithReplc=obtainSummary(linesReplacedPronn2,linesOriginal2,percentageOfSummary)\n",
    "\n",
    "print(reducedSummaryWithReplc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
